{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import krippendorff\n",
    "from scipy.stats import mode\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "from statsmodels.stats.proportion import test_proportions_2indep\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset key\n",
    "df = pd.read_csv(\"output/human_eval/cochrane_full.csv\")\n",
    "df['order'] = df['order'].apply(ast.literal_eval)\n",
    "\n",
    "order_dict = {row['id']: row['order'] for i, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify human eval files\n",
    "files = [\n",
    "    # \"output/human_eval/Full Simplification Human Evaluation - Lj - Cochrane - Arman Criteria.csv\",\n",
    "    # \"output/human_eval/Full Simplification Human Evaluation - Kejian - Cochrane - Arman Criteria.csv\",\n",
    "    # \"output/human_eval/Full Simplification H\n",
    "    # uman Evaluation - Heyuan - Cochrane - Arman Criteria.csv\",\n",
    "    \"output/human_eval/Full Simplification Human Evaluation - Lj - Cochrane.csv\",\n",
    "    \"output/human_eval/Full Simplification Human Evaluation - Kejian - Cochrane.csv\",\n",
    "    \"output/human_eval/Full Simplification Human Evaluation - Heyuan - Cochrane.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df_scores_, order_dict_):\n",
    "    df_scores = df_scores_.copy()\n",
    "    order_dict = order_dict_.copy()\n",
    "\n",
    "    for i, row in df_scores.loc[1:].iterrows():\n",
    "        report_id = row[0]\n",
    "        curr_order = order_dict[int(report_id)]\n",
    "        right_order = np.argsort(curr_order)\n",
    "        \n",
    "        df_scores.iloc[i, 1:5] = np.array(row[1:5])[right_order]\n",
    "        df_scores.iloc[i, 5:9] = np.array(row[5:9])[right_order]\n",
    "    \n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_list = []\n",
    "\n",
    "for f in files:\n",
    "    df_human = pd.read_csv(f) # Read\n",
    "    df_human.iloc[1:,1:] = df_human.iloc[1:,1:].applymap(int) # Cast as int\n",
    "    df_human = reorder(df_human, order_dict) # Reorder by model\n",
    "    df_scores_list.append(df_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108179/983193851.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  scores = mode(scores, axis=2).mode.squeeze(2)\n",
      "/tmp/ipykernel_108179/983193851.py:5: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  scores = mode(scores, axis=2).mode.squeeze(2)\n"
     ]
    }
   ],
   "source": [
    "# Stack all the scores across evaluators\n",
    "scores = np.stack([x.values[1:,1:] for x in df_scores_list], axis=2)\n",
    "\n",
    "# Get the majority vote\n",
    "scores = mode(scores, axis=2).mode.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# df_stacked = np.vstack([x.values[1:,1:] for x in df_scores_list])\n",
    "# for i in range(8):\n",
    "#     x = Counter(df_stacked[:, i])\n",
    "#     print(\"/\".join([str(round(x[k]/90,2)) for k in sorted(x.keys(), reverse=True)]))\n",
    "\n",
    "# for i in range(8):\n",
    "#     x = Counter(scores[:, i])\n",
    "#     print(\"/\".join([str(round(x[k]/30, 2)) for k in sorted(x.keys(), reverse=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1998001998001998\n",
      "1 -0.10559006211180133\n",
      "2 0.015585721468074465\n",
      "3 0.24533634821933292\n",
      "4 0.05066666666666664\n",
      "5 -0.015376984126984183\n",
      "6 0.023319615912208436\n",
      "7 0.40622683469236476\n"
     ]
    }
   ],
   "source": [
    "# Krippendorff's Alpha\n",
    "for col_idx in range(8):\n",
    "    krippen = krippendorff.alpha(\n",
    "        [list(df_scores_list[rater_idx].values[1:,col_idx+1].astype(int)) for \\\n",
    "         rater_idx in range(3)]\n",
    "         )\n",
    "    print(col_idx, krippen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average pairwise Cohen's kappa\n",
    "for col_idx in range(8):\n",
    "    kappa_lst = []\n",
    "    for rater_idx_1 in range(2):\n",
    "        for rater_idx_2 in range(rater_idx_1+1, 3):\n",
    "            pair_kappa = cohen_kappa_score(\n",
    "                y1=df_scores_list[rater_idx_1].values[1:,col_idx+1].astype(int),\n",
    "                y2=df_scores_list[rater_idx_2].values[1:,col_idx+1].astype(int),\n",
    "            )\n",
    "            kappa_lst.append(pair_kappa)\n",
    "    print(col_idx, np.mean(kappa_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7, 0.6333333333333333, 1.3666666666666667, 1.0333333333333334,\n",
       "       1.9666666666666666, 1.5666666666666667, 0.7666666666666667,\n",
       "       1.0333333333333334], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the percentage stats\n",
    "scores.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_read = scores.sum(axis=0)[:4]\n",
    "scores_fact = scores.sum(axis=0)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 51 41 nan\n",
      "0 3 51 31 nan\n",
      "1 2 19 41 nan\n",
      "1 3 19 31 1.1771339097614998e-05\n",
      "0 2 59 23 nan\n",
      "0 3 59 31 nan\n",
      "1 2 47 23 nan\n",
      "1 3 47 31 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyf6/miniconda3/envs/simplification/lib/python3.8/site-packages/statsmodels/stats/proportion.py:1782: RuntimeWarning: invalid value encountered in sqrt\n",
      "  statistic = diff_stat / np.sqrt(var)\n",
      "/home/lyf6/miniconda3/envs/simplification/lib/python3.8/site-packages/statsmodels/stats/proportion.py:1871: RuntimeWarning: invalid value encountered in sqrt\n",
      "  statistic, pvalue = _zstat_generic2(diff_stat, np.sqrt(var),\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis testing\n",
    "for i in [0,1]:\n",
    "    for j in [2,3]:\n",
    "        result = test_proportions_2indep(\n",
    "            count1 = scores_read[i], \n",
    "            nobs1  = 30, \n",
    "            count2 = scores_read[j], \n",
    "            nobs2  = 30, \n",
    "            compare='diff', \n",
    "            alternative='two-sided')\n",
    "        print(i, j, scores_read[i], scores_read[j], result.pvalue)\n",
    "\n",
    "for i in [0,1]:\n",
    "    for j in [2,3]:\n",
    "        result = test_proportions_2indep(\n",
    "            count1 = scores_fact[i], \n",
    "            nobs1  = 30, \n",
    "            count2 = scores_fact[j], \n",
    "            nobs2  = 30, \n",
    "            compare='diff', \n",
    "            alternative='two-sided')\n",
    "        print(i, j, scores_fact[i], scores_fact[j], result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2799999999999999\n",
      "2 -0.30937098844672645\n",
      "3 -0.20000000000000004\n",
      "4 0.15275994865211812\n",
      "5 0.2546583850931675\n",
      "6 -0.3396004700352528\n",
      "7 -0.1538461538461544\n",
      "8 0.2546583850931675\n"
     ]
    }
   ],
   "source": [
    "# Print Fleiss-Kappa agreement scores\n",
    "for i in range(1,9):\n",
    "    temp_df = pd.concat([x.iloc[1:,i] for x in df_scores_list], axis=1)\n",
    "    print(i, fleiss_kappa(aggregate_raters(temp_df)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simplification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
