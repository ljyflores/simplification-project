Traceback (most recent call last):
  File "eval.py", line 14, in <module>
    from utils import get_readability_score
  File "/data/lily/hh638/Health/simplification-project/utils.py", line 18, in <module>
    sent_tokenizer = nltk.data.load("tokenizers/punkt/english.pickle")
  File "/home/lily/hh638/anaconda3/envs/simplification/lib/python3.8/site-packages/nltk/data.py", line 750, in load
    opened_resource = _open(resource_url)
  File "/home/lily/hh638/anaconda3/envs/simplification/lib/python3.8/site-packages/nltk/data.py", line 876, in _open
    return find(path_, path + [""]).open()
  File "/home/lily/hh638/anaconda3/envs/simplification/lib/python3.8/site-packages/nltk/data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError:
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/PY3/english.pickle[0m

  Searched in:
    - '/home/lily/hh638/nltk_data'
    - '/home/lily/hh638/anaconda3/envs/simplification/nltk_data'
    - '/home/lily/hh638/anaconda3/envs/simplification/share/nltk_data'
    - '/home/lily/hh638/anaconda3/envs/simplification/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
    - ''
**********************************************************************

[nltk_data] Downloading package punkt to /home/lily/hh638/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
Traceback (most recent call last):
  File "eval.py", line 15, in <module>
    from utils import get_readability_score
ImportError: cannot import name 'get_readability_score' from 'utils' (/data/lily/hh638/Health/simplification-project/utils.py)
[nltk_data] Downloading package punkt to /home/lily/hh638/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Using custom data configuration default-ae38e4e6b59d597c
Reusing dataset json (/home/lily/hh638/.cache/huggingface/datasets/json/default-ae38e4e6b59d597c/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
Using dataset: asset
Using prediction text file: output/asset_gpt4_detail_128.txt
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 31.53it/s]
Using custom data configuration default-3f91e594c1b18797
Reusing dataset json (/home/lily/hh638/.cache/huggingface/datasets/json/default-3f91e594c1b18797/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 138.93it/s]
{'rouge1': 0.6688, 'rouge2': 0.4439, 'rougeL': 0.6303, 'rougeLsum': 0.6296, 'bert_score': 0.93, 'sari': 39.8131, 'flesch_reading_ease_counts': Counter({'6th grade': 102, '7th grade': 99, '5th grade': 77, '8th & 9th grade': 54, '10th to 12th grade': 19, 'college': 8}), 'flesch_reading_ease_score': 79.3212}
Traceback (most recent call last):
  File "/data/lily/hh638/Health/simplification-project/eval_questeval.py", line 6, in <module>
    questeval = QuestEval(no_cuda=False)
  File "/data/lily/hh638/Health/simplification-project/QuestEval/questeval/questeval_metric.py", line 94, in __init__
    self.hash_files = set(os.listdir(self.log_dir))
FileNotFoundError: [Errno 2] No such file or directory: '/data/lily/hh638/Health/simplification-project/QuestEval/questeval/logs'
/data/lily/hh638/Health/simplification-project/QuestEval/questeval/questeval_metric.py:115: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  self.metric_BERTScore = load_metric("bertscore")
True
cuda
Downloading builder script:   0%|          | 0.00/2.92k [00:00<?, ?B/s]Downloading builder script: 8.10kB [00:00, 12.2MB/s]
WARNING:root:Downloading language model for the spaCy model.
Collecting en-core-web-sm==3.5.0
  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 31.2 MB/s eta 0:00:00
Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.2)
Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)
Requirement already satisfied: pathy>=0.10.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)
Requirement already satisfied: requests<3.0.0,>=2.13.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)
Requirement already satisfied: setuptools in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (66.0.0)
Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)
Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)
Requirement already satisfied: jinja2 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)
Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)
Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)
Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)
Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)
Requirement already satisfied: packaging>=20.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)
Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)
Requirement already satisfied: typer<0.8.0,>=0.3.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)
Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)
Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)
Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)
Requirement already satisfied: numpy>=1.15.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)
Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)
Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)
Requirement already satisfied: typing-extensions>=4.2.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)
Requirement already satisfied: charset-normalizer<4,>=2 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)
Requirement already satisfied: confection<1.0.0,>=0.0.1 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)
Requirement already satisfied: blis<0.8.0,>=0.7.8 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)
Requirement already satisfied: click<9.0.0,>=7.1.1 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)
Requirement already satisfied: MarkupSafe>=2.0 in /data/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)
Installing collected packages: en-core-web-sm
Successfully installed en-core-web-sm-3.5.0
[38;5;2m✔ Download and installation successful[0m
You can now load the package via spacy.load('en_core_web_sm')
Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 17.1MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 1.79k/1.79k [00:00<00:00, 174kB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/1.91k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 1.91k/1.91k [00:00<00:00, 780kB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.41k/1.41k [00:00<00:00, 569kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/892M [00:00<00:23, 37.0MB/s]Downloading pytorch_model.bin:   2%|▏         | 21.0M/892M [00:00<00:22, 39.1MB/s]Downloading pytorch_model.bin:   4%|▎         | 31.5M/892M [00:00<00:20, 42.5MB/s]Downloading pytorch_model.bin:   5%|▍         | 41.9M/892M [00:00<00:19, 44.5MB/s]Downloading pytorch_model.bin:   6%|▌         | 52.4M/892M [00:01<00:18, 46.1MB/s]Downloading pytorch_model.bin:   7%|▋         | 62.9M/892M [00:01<00:17, 46.7MB/s]Downloading pytorch_model.bin:   8%|▊         | 73.4M/892M [00:01<00:19, 41.8MB/s]Downloading pytorch_model.bin:   9%|▉         | 83.9M/892M [00:02<00:22, 36.3MB/s]Downloading pytorch_model.bin:  11%|█         | 94.4M/892M [00:02<00:22, 35.6MB/s]Downloading pytorch_model.bin:  12%|█▏        | 105M/892M [00:02<00:21, 36.0MB/s] Downloading pytorch_model.bin:  13%|█▎        | 115M/892M [00:02<00:20, 37.3MB/s]Downloading pytorch_model.bin:  14%|█▍        | 126M/892M [00:03<00:19, 38.7MB/s]Downloading pytorch_model.bin:  15%|█▌        | 136M/892M [00:03<00:18, 40.3MB/s]Downloading pytorch_model.bin:  16%|█▋        | 147M/892M [00:03<00:17, 42.4MB/s]Downloading pytorch_model.bin:  18%|█▊        | 157M/892M [00:03<00:16, 44.3MB/s]Downloading pytorch_model.bin:  19%|█▉        | 168M/892M [00:04<00:15, 46.2MB/s]Downloading pytorch_model.bin:  20%|█▉        | 178M/892M [00:04<00:15, 47.2MB/s]Downloading pytorch_model.bin:  21%|██        | 189M/892M [00:04<00:14, 49.2MB/s]Downloading pytorch_model.bin:  22%|██▏       | 199M/892M [00:04<00:13, 51.3MB/s]Downloading pytorch_model.bin:  24%|██▎       | 210M/892M [00:04<00:13, 52.0MB/s]Downloading pytorch_model.bin:  25%|██▍       | 220M/892M [00:05<00:12, 54.2MB/s]Downloading pytorch_model.bin:  26%|██▌       | 231M/892M [00:05<00:11, 56.3MB/s]Downloading pytorch_model.bin:  27%|██▋       | 241M/892M [00:05<00:12, 50.8MB/s]Downloading pytorch_model.bin:  28%|██▊       | 252M/892M [00:05<00:11, 54.2MB/s]Downloading pytorch_model.bin:  29%|██▉       | 262M/892M [00:05<00:10, 57.4MB/s]Downloading pytorch_model.bin:  31%|███       | 273M/892M [00:05<00:10, 60.3MB/s]Downloading pytorch_model.bin:  32%|███▏      | 283M/892M [00:06<00:09, 62.6MB/s]Downloading pytorch_model.bin:  33%|███▎      | 294M/892M [00:06<00:09, 65.0MB/s]Downloading pytorch_model.bin:  34%|███▍      | 304M/892M [00:06<00:08, 67.1MB/s]Downloading pytorch_model.bin:  35%|███▌      | 315M/892M [00:06<00:08, 69.1MB/s]Downloading pytorch_model.bin:  36%|███▋      | 325M/892M [00:06<00:08, 70.6MB/s]Downloading pytorch_model.bin:  38%|███▊      | 336M/892M [00:06<00:07, 72.1MB/s]Downloading pytorch_model.bin:  39%|███▉      | 346M/892M [00:06<00:07, 71.1MB/s]Downloading pytorch_model.bin:  40%|███▉      | 357M/892M [00:07<00:07, 71.4MB/s]Downloading pytorch_model.bin:  41%|████      | 367M/892M [00:07<00:07, 72.5MB/s]Downloading pytorch_model.bin:  42%|████▏     | 377M/892M [00:07<00:06, 74.5MB/s]Downloading pytorch_model.bin:  44%|████▎     | 388M/892M [00:07<00:06, 76.3MB/s]Downloading pytorch_model.bin:  45%|████▍     | 398M/892M [00:07<00:06, 77.0MB/s]Downloading pytorch_model.bin:  46%|████▌     | 409M/892M [00:07<00:06, 78.2MB/s]Downloading pytorch_model.bin:  47%|████▋     | 419M/892M [00:07<00:05, 79.4MB/s]Downloading pytorch_model.bin:  48%|████▊     | 430M/892M [00:07<00:05, 80.2MB/s]Downloading pytorch_model.bin:  49%|████▉     | 440M/892M [00:08<00:05, 80.9MB/s]Downloading pytorch_model.bin:  51%|█████     | 451M/892M [00:08<00:05, 82.1MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 461M/892M [00:08<00:05, 82.9MB/s]Downloading pytorch_model.bin:  53%|█████▎    | 472M/892M [00:08<00:05, 83.6MB/s]Downloading pytorch_model.bin:  54%|█████▍    | 482M/892M [00:08<00:04, 84.2MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 493M/892M [00:08<00:04, 83.4MB/s]Downloading pytorch_model.bin:  56%|█████▋    | 503M/892M [00:08<00:04, 77.7MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 514M/892M [00:09<00:05, 74.4MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 524M/892M [00:09<00:05, 71.5MB/s]Downloading pytorch_model.bin:  60%|█████▉    | 535M/892M [00:09<00:05, 69.7MB/s]Downloading pytorch_model.bin:  61%|██████    | 545M/892M [00:09<00:04, 70.4MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 556M/892M [00:09<00:04, 71.2MB/s]Downloading pytorch_model.bin:  64%|██████▎   | 566M/892M [00:09<00:04, 71.9MB/s]Downloading pytorch_model.bin:  65%|██████▍   | 577M/892M [00:10<00:05, 60.8MB/s]Downloading pytorch_model.bin:  66%|██████▌   | 587M/892M [00:10<00:06, 46.8MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 598M/892M [00:10<00:07, 41.9MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 608M/892M [00:11<00:07, 35.6MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 619M/892M [00:11<00:08, 33.9MB/s]Downloading pytorch_model.bin:  71%|███████   | 629M/892M [00:11<00:08, 32.8MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 640M/892M [00:12<00:07, 33.7MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 650M/892M [00:12<00:07, 34.3MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 661M/892M [00:12<00:06, 33.3MB/s]Downloading pytorch_model.bin:  75%|███████▌  | 671M/892M [00:13<00:07, 29.9MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 682M/892M [00:13<00:08, 24.5MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 692M/892M [00:14<00:09, 21.2MB/s]Downloading pytorch_model.bin:  79%|███████▉  | 703M/892M [00:15<00:09, 19.0MB/s]Downloading pytorch_model.bin:  80%|███████▉  | 713M/892M [00:15<00:10, 17.5MB/s]Downloading pytorch_model.bin:  81%|████████  | 724M/892M [00:16<00:10, 16.7MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 734M/892M [00:17<00:11, 14.1MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 744M/892M [00:18<00:10, 14.1MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 755M/892M [00:18<00:08, 15.6MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 765M/892M [00:19<00:07, 17.7MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 776M/892M [00:19<00:05, 20.4MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 786M/892M [00:19<00:04, 23.1MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 797M/892M [00:20<00:03, 26.0MB/s]Downloading pytorch_model.bin:  91%|█████████ | 807M/892M [00:20<00:02, 29.1MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 818M/892M [00:20<00:02, 32.0MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 828M/892M [00:20<00:01, 34.9MB/s]Downloading pytorch_model.bin:  94%|█████████▍| 839M/892M [00:21<00:01, 37.8MB/s]Downloading pytorch_model.bin:  95%|█████████▌| 849M/892M [00:21<00:01, 40.6MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 860M/892M [00:21<00:00, 43.1MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 870M/892M [00:21<00:00, 45.8MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 881M/892M [00:21<00:00, 48.6MB/s]Downloading pytorch_model.bin: 100%|█████████▉| 891M/892M [00:22<00:00, 50.8MB/s]Downloading pytorch_model.bin: 100%|██████████| 892M/892M [00:22<00:00, 40.4MB/s]
Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 19.1MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 1.79k/1.79k [00:00<00:00, 169kB/s]
Downloading (…)okenizer_config.json:   0%|          | 0.00/1.91k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 1.91k/1.91k [00:00<00:00, 628kB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 1.41k/1.41k [00:00<00:00, 301kB/s]
Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/892M [00:00<00:16, 53.0MB/s]Downloading pytorch_model.bin:   2%|▏         | 21.0M/892M [00:00<00:13, 62.5MB/s]Downloading pytorch_model.bin:   4%|▎         | 31.5M/892M [00:00<00:12, 67.8MB/s]Downloading pytorch_model.bin:   5%|▍         | 41.9M/892M [00:00<00:12, 70.4MB/s]Downloading pytorch_model.bin:   6%|▌         | 52.4M/892M [00:00<00:11, 72.6MB/s]Downloading pytorch_model.bin:   7%|▋         | 62.9M/892M [00:00<00:11, 74.5MB/s]Downloading pytorch_model.bin:   8%|▊         | 73.4M/892M [00:01<00:10, 75.4MB/s]Downloading pytorch_model.bin:   9%|▉         | 83.9M/892M [00:01<00:10, 76.4MB/s]Downloading pytorch_model.bin:  11%|█         | 94.4M/892M [00:01<00:10, 76.9MB/s]Downloading pytorch_model.bin:  12%|█▏        | 105M/892M [00:01<00:10, 77.8MB/s] Downloading pytorch_model.bin:  13%|█▎        | 115M/892M [00:01<00:09, 78.5MB/s]Downloading pytorch_model.bin:  14%|█▍        | 126M/892M [00:01<00:09, 79.2MB/s]Downloading pytorch_model.bin:  15%|█▌        | 136M/892M [00:01<00:09, 79.5MB/s]Downloading pytorch_model.bin:  16%|█▋        | 147M/892M [00:01<00:09, 80.1MB/s]Downloading pytorch_model.bin:  18%|█▊        | 157M/892M [00:02<00:09, 80.1MB/s]Downloading pytorch_model.bin:  19%|█▉        | 168M/892M [00:02<00:09, 75.6MB/s]Downloading pytorch_model.bin:  20%|█▉        | 178M/892M [00:02<00:09, 73.1MB/s]Downloading pytorch_model.bin:  21%|██        | 189M/892M [00:02<00:09, 71.0MB/s]Downloading pytorch_model.bin:  22%|██▏       | 199M/892M [00:02<00:09, 70.0MB/s]Downloading pytorch_model.bin:  24%|██▎       | 210M/892M [00:02<00:09, 70.3MB/s]Downloading pytorch_model.bin:  25%|██▍       | 220M/892M [00:02<00:09, 70.8MB/s]Downloading pytorch_model.bin:  26%|██▌       | 231M/892M [00:03<00:09, 71.5MB/s]Downloading pytorch_model.bin:  27%|██▋       | 241M/892M [00:03<00:08, 72.4MB/s]Downloading pytorch_model.bin:  28%|██▊       | 252M/892M [00:03<00:09, 67.8MB/s]Downloading pytorch_model.bin:  29%|██▉       | 262M/892M [00:03<00:09, 64.1MB/s]Downloading pytorch_model.bin:  31%|███       | 273M/892M [00:03<00:09, 62.3MB/s]Downloading pytorch_model.bin:  32%|███▏      | 283M/892M [00:03<00:09, 61.4MB/s]Downloading pytorch_model.bin:  33%|███▎      | 294M/892M [00:04<00:09, 61.5MB/s]Downloading pytorch_model.bin:  34%|███▍      | 304M/892M [00:04<00:09, 62.2MB/s]Downloading pytorch_model.bin:  35%|███▌      | 315M/892M [00:04<00:09, 62.7MB/s]Downloading pytorch_model.bin:  36%|███▋      | 325M/892M [00:04<00:08, 63.8MB/s]Downloading pytorch_model.bin:  38%|███▊      | 336M/892M [00:04<00:08, 65.2MB/s]Downloading pytorch_model.bin:  39%|███▉      | 346M/892M [00:04<00:08, 66.6MB/s]Downloading pytorch_model.bin:  40%|███▉      | 357M/892M [00:05<00:07, 67.7MB/s]Downloading pytorch_model.bin:  41%|████      | 367M/892M [00:05<00:07, 68.9MB/s]Downloading pytorch_model.bin:  42%|████▏     | 377M/892M [00:05<00:07, 69.6MB/s]Downloading pytorch_model.bin:  44%|████▎     | 388M/892M [00:05<00:07, 70.0MB/s]Downloading pytorch_model.bin:  45%|████▍     | 398M/892M [00:05<00:06, 71.2MB/s]Downloading pytorch_model.bin:  46%|████▌     | 409M/892M [00:05<00:06, 72.5MB/s]Downloading pytorch_model.bin:  47%|████▋     | 419M/892M [00:05<00:06, 73.6MB/s]Downloading pytorch_model.bin:  48%|████▊     | 430M/892M [00:06<00:06, 74.6MB/s]Downloading pytorch_model.bin:  49%|████▉     | 440M/892M [00:06<00:05, 75.7MB/s]Downloading pytorch_model.bin:  51%|█████     | 451M/892M [00:06<00:05, 75.8MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 461M/892M [00:06<00:05, 76.3MB/s]Downloading pytorch_model.bin:  53%|█████▎    | 472M/892M [00:06<00:05, 73.8MB/s]Downloading pytorch_model.bin:  54%|█████▍    | 482M/892M [00:06<00:05, 71.3MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 493M/892M [00:06<00:05, 67.0MB/s]Downloading pytorch_model.bin:  56%|█████▋    | 503M/892M [00:07<00:05, 66.0MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 514M/892M [00:07<00:05, 64.4MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 524M/892M [00:07<00:05, 65.0MB/s]Downloading pytorch_model.bin:  60%|█████▉    | 535M/892M [00:07<00:05, 64.9MB/s]Downloading pytorch_model.bin:  61%|██████    | 545M/892M [00:07<00:05, 65.1MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 556M/892M [00:07<00:05, 65.3MB/s]Downloading pytorch_model.bin:  64%|██████▎   | 566M/892M [00:08<00:04, 66.0MB/s]Downloading pytorch_model.bin:  65%|██████▍   | 577M/892M [00:08<00:04, 67.4MB/s]Downloading pytorch_model.bin:  66%|██████▌   | 587M/892M [00:08<00:04, 69.0MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 598M/892M [00:08<00:04, 69.5MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 608M/892M [00:08<00:04, 62.6MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 619M/892M [00:08<00:04, 66.2MB/s]Downloading pytorch_model.bin:  71%|███████   | 629M/892M [00:09<00:03, 68.5MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 640M/892M [00:09<00:03, 68.1MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 650M/892M [00:09<00:03, 67.7MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 661M/892M [00:09<00:03, 68.2MB/s]Downloading pytorch_model.bin:  75%|███████▌  | 671M/892M [00:09<00:03, 71.0MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 682M/892M [00:09<00:02, 73.1MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 692M/892M [00:09<00:02, 71.0MB/s]Downloading pytorch_model.bin:  79%|███████▉  | 703M/892M [00:10<00:02, 67.7MB/s]Downloading pytorch_model.bin:  80%|███████▉  | 713M/892M [00:10<00:02, 66.5MB/s]Downloading pytorch_model.bin:  81%|████████  | 724M/892M [00:10<00:02, 64.9MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 734M/892M [00:10<00:02, 64.8MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 744M/892M [00:10<00:02, 65.6MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 755M/892M [00:10<00:02, 65.5MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 765M/892M [00:11<00:01, 66.7MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 776M/892M [00:11<00:01, 67.4MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 786M/892M [00:11<00:01, 68.6MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 797M/892M [00:11<00:01, 70.1MB/s]Downloading pytorch_model.bin:  91%|█████████ | 807M/892M [00:11<00:01, 71.4MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 818M/892M [00:11<00:01, 72.3MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 828M/892M [00:11<00:00, 73.1MB/s]Downloading pytorch_model.bin:  94%|█████████▍| 839M/892M [00:12<00:00, 74.0MB/s]Downloading pytorch_model.bin:  95%|█████████▌| 849M/892M [00:12<00:00, 75.3MB/s]Downloading pytorch_model.bin:  96%|█████████▋| 860M/892M [00:12<00:00, 76.4MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 870M/892M [00:12<00:00, 60.8MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 881M/892M [00:12<00:00, 65.3MB/s]Downloading pytorch_model.bin: 100%|█████████▉| 891M/892M [00:12<00:00, 69.4MB/s]Downloading pytorch_model.bin: 100%|██████████| 892M/892M [00:12<00:00, 68.9MB/s]
/home/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
/data/lily/hh638/Health/simplification-project/QuestEval/questeval/questeval_metric.py:115: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  self.metric_BERTScore = load_metric("bertscore")
/home/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
True
cuda
Using dataset: asset
Using prediction text file: output/asset_gpt4_detail_128.txt
{'questeval_ref': 0.646785983474057, 'questeval_ref_std': 0.145955099538762, 'questeval_no_ref': 0.5670096244739451, 'questeval_no_ref_std': 0.15314886292138782}
