Using custom data configuration default-71d2aca9cc035ec7
Using dataset: asset_context_all
Using prediction text file: output/asset_context_all_gpt4_basic_128.txt
Downloading and preparing dataset json/default to /home/lily/hh638/.cache/huggingface/datasets/json/default-71d2aca9cc035ec7/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 5974.79it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 436.91it/s]
Dataset json downloaded and prepared to /home/lily/hh638/.cache/huggingface/datasets/json/default-71d2aca9cc035ec7/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 137.30it/s]
Using custom data configuration default-fde15bd3b1a34614
Reusing dataset json (/home/lily/hh638/.cache/huggingface/datasets/json/default-fde15bd3b1a34614/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 137.18it/s]
{'rouge1': 0.6464, 'rouge2': 0.4534, 'rougeL': 0.6063, 'rougeLsum': 0.6065, 'bert_score': 0.9216, 'sari': 45.4366, 'flesch_reading_ease_counts': Counter({'10th to 12th grade': 84, 'college': 78, '8th & 9th grade': 65, '7th grade': 60, '6th grade': 29, 'college graduate': 21, '5th grade': 18, 'professional': 4}), 'flesch_reading_ease_score': 59.1325}
/data/lily/hh638/Health/simplification-project/QuestEval/questeval/questeval_metric.py:115: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  self.metric_BERTScore = load_metric("bertscore")
/home/lily/hh638/anaconda3/envs/questeval/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
True
cuda
Using dataset: asset_context_all
Using prediction text file: output/asset_context_all_gpt4_basic_128.txt
{'questeval_ref': 0.6662162587588302, 'questeval_ref_std': 0.11659142884240786, 'questeval_no_ref': 0.5867315999672448, 'questeval_no_ref_std': 0.12209002359431376}
